{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6709368",
   "metadata": {},
   "source": [
    "# PyRAG Live Data\n",
    "\n",
    "This notebook gets files from a S3 bucket, creates embeddings and inserts them into the database.\n",
    "\n",
    "Supported file types: csv, json, pdf, txt\n",
    "Supported S3 actions: upload, update, delete\n",
    "\n",
    "- Loading a new file, a new table is created.\n",
    "- Updating a file, a table is deleted and created anew.\n",
    "- Deleting a file, a table is deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f841ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install singlestoredb boto3 transformers pandas==2.1.4 semantic-text-splitter python-dotenv PyPDF2 langchain sentence_transformers datetime --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f929cf4d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import singlestoredb as s2\n",
    "from typing import Any, Callable, Hashable, List, Optional\n",
    "from datetime import datetime, timezone\n",
    "from PyPDF2 import PdfReader\n",
    "from semantic_text_splitter import CharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb49c508",
   "metadata": {},
   "source": [
    "To get the AWS values, follow these steps:\n",
    "1. Go to [My security credentials](https://us-east-1.console.aws.amazon.com/iam/home?region=us-east-1#/security_credentials)\n",
    "2. Find the \"Access keys\" section and click on the \"Create access key\" button\n",
    "3. Copy and paste values\n",
    "\n",
    "The `aws_bucket_name` is your bucket name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d5cc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = connection_url.split('/')[-1] or 'pyrag'\n",
    "aws_access_key_id = 'AWS_ACCESS_KEY_ID'\n",
    "aws_secret_access_key = 'AWS_SECRET_ACCESS_KEY'\n",
    "aws_bucket_name = 'AWS_BUCKET_NAME'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161f228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection = s2.connect(connection_url)\n",
    "s3 = boto3.client('s3', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key)\n",
    "text_splitter = CharacterTextSplitter(trim_chunks=False)\n",
    "embedding_model = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1d2182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text: str):\n",
    "    return text_splitter.chunks(text, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97644bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_extension(name: str):\n",
    "    return os.path.splitext(name)[1][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e9e73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding(input):\n",
    "    return embedding_model.embed_query(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b469a53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(table_name: str):\n",
    "    with db_connection.cursor() as cursor:\n",
    "        cursor.execute(f'''\n",
    "          CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "            id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            content LONGTEXT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci,\n",
    "            created_at DATETIME,\n",
    "            v VECTOR(768) NOT NULL\n",
    "          )\n",
    "        ''')\n",
    "\n",
    "        cursor.execute(f'''\n",
    "          ALTER TABLE {table_name} ADD VECTOR INDEX vector_index (v)\n",
    "          INDEX_OPTIONS '{{\"index_type\": \"IVF_PQ\", \"nlist\": 4000}}'\n",
    "        ''')\n",
    "\n",
    "        cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e39da4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_table(table_name: str):\n",
    "    with db_connection.cursor() as cursor:\n",
    "        cursor.execute(f'DROP TABLE IF EXISTS {table_name}')\n",
    "        cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97824094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_names(table_name: str | None = None):\n",
    "    try:\n",
    "        with db_connection.cursor() as cursor:\n",
    "            query = f'''\n",
    "              SELECT TABLE_NAME\n",
    "              FROM INFORMATION_SCHEMA.TABLES\n",
    "              WHERE TABLE_SCHEMA = '{db_name}'\n",
    "            '''\n",
    "\n",
    "            if table_name:\n",
    "                query += f\" AND TABLE_NAME = '{table_name}'\"\n",
    "\n",
    "            cursor.execute(query)\n",
    "            result = cursor.fetchall()\n",
    "\n",
    "            if result:\n",
    "                return [i[0] if type(i) == tuple else '' for i in result]\n",
    "\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ea4f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_table_up_to_date(table_name: str, created_at: datetime):\n",
    "    def is_exists():\n",
    "        try:\n",
    "            return bool(len(get_table_names(table_name)))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return False\n",
    "\n",
    "    def is_latest():\n",
    "        try:\n",
    "            with db_connection.cursor() as cursor:\n",
    "                cursor.execute(f'''\n",
    "                  SELECT created_at FROM {table_name} LIMIT 1\n",
    "                ''')\n",
    "                result = cursor.fetchone()\n",
    "\n",
    "                if not type(result) == tuple:\n",
    "                    return False\n",
    "\n",
    "                return result[0] >= created_at\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return False\n",
    "\n",
    "    return is_exists() and is_latest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5dfb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_content_to_df(content: Any, extension: str):\n",
    "    def assign_created_at(df: pd.DataFrame):\n",
    "        df['created_at'] = datetime.now().astimezone(timezone.utc).replace(tzinfo=None)\n",
    "\n",
    "    if extension == 'csv':\n",
    "        df = pd.read_csv(io.StringIO(content.decode('utf-8')))\n",
    "        assign_created_at(df)\n",
    "        return df\n",
    "\n",
    "    if extension == 'json':\n",
    "        df = pd.read_json(io.StringIO(content.decode('utf-8')))\n",
    "        assign_created_at(df)\n",
    "        return df\n",
    "\n",
    "    if extension == 'pdf':\n",
    "        text = ''\n",
    "        reader = PdfReader(io.BytesIO(content))\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "        df = pd.DataFrame(split_text(text), columns=['text'])\n",
    "        assign_created_at(df)\n",
    "        return df\n",
    "\n",
    "    if extension == 'txt':\n",
    "        df = pd.DataFrame(split_text(content.decode('utf-8')), columns=['text'])\n",
    "        assign_created_at(df)\n",
    "        return df\n",
    "\n",
    "    raise ValueError('Unsupported file format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec872592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(\n",
    "    df: pd.DataFrame,\n",
    "    customize_row: Optional[Callable[[Hashable, pd.Series, pd.DataFrame], None]],\n",
    "    reserved_keys: List[str] = []\n",
    "):\n",
    "    for i, row in df.iterrows():\n",
    "        content = row.to_json()\n",
    "        df.at[i, 'content'] = content\n",
    "        embedding = create_embedding(content)\n",
    "        df.at[i, 'embedding'] = str(embedding)\n",
    "\n",
    "        if customize_row:\n",
    "            customize_row(i, row, df)\n",
    "\n",
    "    return df.drop(columns=[col for col in df.columns if col not in [*reserved_keys, 'content', 'embedding']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bb66a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_df(df: pd.DataFrame, table_name: str):\n",
    "    with db_connection.cursor() as cursor:\n",
    "        cursor.executemany(f'''\n",
    "            INSERT INTO {table_name} (id, created_at, content, v)\n",
    "            VALUES (%s, %s, %s, %s)\n",
    "        ''', df.to_records(index=True).tolist())\n",
    "        cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7889c643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_file_name(file_name):\n",
    "    return re.sub(r'\\W', '_', file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86552680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def s3_process_files(on_file):\n",
    "    def get_files():\n",
    "        try:\n",
    "            response = s3.list_objects_v2(Bucket=aws_bucket_name)\n",
    "            files = response.get('Contents')\n",
    "\n",
    "            if not files:\n",
    "                return []\n",
    "\n",
    "            return files\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return []\n",
    "\n",
    "    def get_file_content(key: str):\n",
    "        try:\n",
    "            obj = s3.get_object(Bucket=aws_bucket_name, Key=key)\n",
    "            content = obj['Body'].read()\n",
    "            return content\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return ''\n",
    "\n",
    "    for file in get_files():\n",
    "        file_name = file['Key']\n",
    "\n",
    "        on_file({\n",
    "            'name': file_name,\n",
    "            'content': get_file_content(file_name),\n",
    "            'updated_at': datetime.strptime(\n",
    "                str(file['LastModified']), '%Y-%m-%d %H:%M:%S%z'\n",
    "            ).astimezone(timezone.utc).replace(tzinfo=None)\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220a9442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    existed_table_names = get_table_names()\n",
    "    file_table_names = []\n",
    "\n",
    "    def on_file(file):\n",
    "        table_name = format_file_name(file['name'])\n",
    "        file_table_names.append(table_name)\n",
    "\n",
    "        if is_table_up_to_date(table_name, file['updated_at']):\n",
    "            print(table_name, 'is up to date')\n",
    "            return\n",
    "\n",
    "        df = file_content_to_df(file['content'], get_file_extension(file['name']))\n",
    "\n",
    "        drop_table(table_name)\n",
    "        create_table(table_name)\n",
    "\n",
    "        def customize_row(i: Hashable, _, df: pd.DataFrame):\n",
    "            df.at[i, 'created_at'] = file['updated_at']\n",
    "\n",
    "        insert_df(prepare_df(df, customize_row=customize_row, reserved_keys=['created_at']), table_name)\n",
    "        print(table_name, 'updated' if table_name in existed_table_names else 'inserted')\n",
    "\n",
    "    for file_process in [s3_process_files]:\n",
    "        try:\n",
    "            file_process(on_file)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "    for existed_table_name in existed_table_names:\n",
    "        if not existed_table_name in file_table_names:\n",
    "            drop_table(existed_table_name)\n",
    "            print(existed_table_name, 'deleted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1a897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(table_name: str, query: str,):\n",
    "    query_embedding = create_embedding(query)\n",
    "    v_length = len(query_embedding)\n",
    "    with db_connection.cursor() as cursor:\n",
    "        cursor.execute(f'''\n",
    "            SELECT content, v <*> '{query_embedding}' :> VECTOR({v_length}) AS similarity\n",
    "            FROM {table_name}\n",
    "            ORDER BY similarity USE INDEX (vector_index) DESC\n",
    "            LIMIT 5\n",
    "        ''')\n",
    "        return cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84279364",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ae570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(semantic_search('THE_STORY_THE_FIELD_GUIDE_pdf', 'concepts at the heart of Data Science'))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
